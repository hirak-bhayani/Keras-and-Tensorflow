{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfBg1C5NB3X0"
   },
   "source": [
    "# Distributed Training with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHxb-dlhMIzW"
   },
   "source": [
    "**Learning Objectives**\n",
    "\n",
    "1. How to define distribution strategy and set input pipeline.\n",
    "2. How to create the Keras model.\n",
    "3. How to define the callbacks.\n",
    "4. How to train and evaluate the model.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The `tf.distribute.Strategy` API provides an abstraction for distributing your training\n",
    "across multiple processing units. The goal is to allow users to enable distributed training using existing models and training code, with minimal changes.\n",
    "\n",
    "This notebook uses the `tf.distribute.MirroredStrategy`, which\n",
    "does in-graph replication with synchronous training on many GPUs on one machine.\n",
    "Essentially, it copies all of the model's variables to each processor.\n",
    "Then, it uses [all-reduce](http://mpitutorial.com/tutorials/mpi-reduce-and-allreduce/) to combine the gradients from all processors and applies the combined value to all copies of the model.\n",
    "\n",
    "`MirroredStrategy` is one of several distribution strategy available in TensorFlow core. You can read about more strategies at [distribution strategy guide](https://raw.githubusercontent.com/tensorflow/docs/master/site/en/guide/distributed_training.ipynb).\n",
    "\n",
    "Each learning objective will correspond to a __#TODO__ in this student lab notebook -- try to complete this notebook first and then review the [solution notebook](../solutions/keras.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUXex9ctTuDB"
   },
   "source": [
    "### Keras API\n",
    "\n",
    "This example uses the `tf.keras` API to build the model and training loop. For custom training loops, see the [tf.distribute.Strategy with training loops](training_loops.ipynb) tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dney9v7BsJij"
   },
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dill in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (0.3.1.1)\n",
      "Collecting tensorflow-data-validation[visualization]\n",
      "  Downloading tensorflow_data_validation-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: absl-py<2.0.0,>=0.9 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow-data-validation[visualization]) (1.4.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow-data-validation[visualization]) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow-data-validation[visualization]) (1.24.4)\n",
      "Collecting pandas<2,>=1.0 (from tensorflow-data-validation[visualization])\n",
      "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting pyarrow<11,>=10 (from tensorflow-data-validation[visualization])\n",
      "  Downloading pyarrow-10.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting pyfarmhash<0.4,>=0.2.2 (from tensorflow-data-validation[visualization])\n",
      "  Downloading pyfarmhash-0.3.2.tar.gz (99 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six<2,>=1.12 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow-data-validation[visualization]) (1.17.0)\n",
      "Collecting tensorflow<2.17,>=2.16 (from tensorflow-data-validation[visualization])\n",
      "  Downloading tensorflow-2.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting tensorflow-metadata<1.17,>=1.16.0 (from tensorflow-data-validation[visualization])\n",
      "  Downloading tensorflow_metadata-1.16.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tfx-bsl<1.17,>=1.16.0 (from tensorflow-data-validation[visualization])\n",
      "  Downloading tfx_bsl-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting apache-beam<3,>=2.47 (from apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization])\n",
      "  Downloading apache_beam-2.69.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Collecting protobuf<5,>=3.20.3 (from tensorflow-data-validation[visualization])\n",
      "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Collecting ipython<8,>=7 (from tensorflow-data-validation[visualization])\n",
      "  Downloading ipython-7.34.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (1.7)\n",
      "Requirement already satisfied: cryptography<48.0.0,>=39.0.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (42.0.8)\n",
      "Requirement already satisfied: orjson<4,>=3.9.7 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (3.11.3)\n",
      "Requirement already satisfied: fastavro<2,>=0.23.6 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (1.12.0)\n",
      "Requirement already satisfied: fasteners<1.0,>=0.3 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (0.20)\n",
      "Collecting grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<1.66.0,<2,>=1.33.1 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization])\n",
      "  Downloading grpcio-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (2.7.3)\n",
      "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (0.21.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (4.25.1)\n",
      "Collecting jsonpickle<4.0.0,>=3.0.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization])\n",
      "  Downloading jsonpickle-3.4.2-py3-none-any.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: objsize<0.8.0,>=0.6.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (0.6.1)\n",
      "Requirement already satisfied: packaging>=22.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (25.0)\n",
      "Requirement already satisfied: pymongo<5.0.0,>=3.8.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (3.13.0)\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (1.26.1)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2018.3 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (2025.2)\n",
      "Collecting redis<6,>=5.0.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization])\n",
      "  Downloading redis-5.3.1-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: regex>=2020.6.8 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (2025.9.18)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.4 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (2.32.5)\n",
      "Collecting sortedcontainers>=2.4.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization])\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (4.15.0)\n",
      "Requirement already satisfied: zstandard<1,>=0.18.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (0.25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=3.12 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (6.0.3)\n",
      "Collecting beartype<0.22.0,>=0.21.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization])\n",
      "  Downloading beartype-0.21.0-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting pyarrow-hotfix<1 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization])\n",
      "  Downloading pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: cachetools<7,>=3.1.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (4.2.4)\n",
      "Requirement already satisfied: google-api-core<3,>=2.0.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (2.26.0)\n",
      "Requirement already satisfied: google-apitools<0.5.32,>=0.5.31 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (0.5.31)\n",
      "Requirement already satisfied: google-auth<3,>=1.18.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (2.41.1)\n",
      "Requirement already satisfied: google-auth-httplib2<0.3.0,>=0.1.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (0.1.1)\n",
      "Collecting google-cloud-datastore<3,>=2.0.0 (from apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization])\n",
      "  Downloading google_cloud_datastore-2.21.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: google-cloud-pubsub<3,>=2.1.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (2.21.4)\n",
      "Requirement already satisfied: google-cloud-pubsublite<2,>=1.2.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (1.12.0)\n",
      "Requirement already satisfied: google-cloud-storage<3,>=2.18.2 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (2.19.0)\n",
      "Requirement already satisfied: google-cloud-bigquery<4,>=2.0.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (3.29.0)\n",
      "Requirement already satisfied: google-cloud-bigquery-storage<3,>=2.6.3 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (2.16.2)\n",
      "Requirement already satisfied: google-cloud-core<3,>=2.0.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (2.4.3)\n",
      "Collecting google-cloud-bigtable<3,>=2.19.0 (from apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization])\n",
      "  Downloading google_cloud_bigtable-2.34.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: google-cloud-spanner<4,>=3.0.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (3.46.0)\n",
      "Requirement already satisfied: google-cloud-dlp<4,>=3.0.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (3.18.0)\n",
      "Collecting google-cloud-language<3,>=2.0 (from apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization])\n",
      "  Downloading google_cloud_language-2.18.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Collecting google-cloud-secret-manager<3,>=2.0 (from apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization])\n",
      "  Downloading google_cloud_secret_manager-2.25.0-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting google-cloud-videointelligence<3,>=2.0 (from apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization])\n",
      "  Downloading google_cloud_videointelligence-2.17.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: google-cloud-vision<4,>=2 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (3.7.2)\n",
      "Requirement already satisfied: google-cloud-recommendations-ai<0.11.0,>=0.1.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (0.7.1)\n",
      "Requirement already satisfied: google-cloud-aiplatform<2.0,>=1.26.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (1.60.0)\n",
      "Collecting cloud-sql-python-connector<2.0.0,>=1.18.2 (from apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization])\n",
      "  Downloading cloud_sql_python_connector-1.18.5-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting python-tds>=1.16.1 (from apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization])\n",
      "  Downloading python_tds-1.17.1-py3-none-any.whl.metadata (804 bytes)\n",
      "Collecting pg8000>=1.31.1 (from apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization])\n",
      "  Downloading pg8000-1.31.5-py3-none-any.whl.metadata (88 kB)\n",
      "Collecting PyMySQL>=1.1.0 (from apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization])\n",
      "  Downloading pymysql-1.1.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: keyrings.google-artifactregistry-auth in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (1.1.2)\n",
      "Requirement already satisfied: aiofiles in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from cloud-sql-python-connector<2.0.0,>=1.18.2->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (22.1.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from cloud-sql-python-connector<2.0.0,>=1.18.2->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (3.13.0)\n",
      "Collecting dnspython>=2.0.0 (from cloud-sql-python-connector<2.0.0,>=1.18.2->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization])\n",
      "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from cryptography<48.0.0,>=39.0.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (2.0.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-api-core<3,>=2.0.0->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (1.63.1)\n",
      "Requirement already satisfied: oauth2client>=1.4.12 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-apitools<0.5.32,>=0.5.31->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (4.1.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (4.9.1)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (1.12.3)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (2.1.2)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (2.12.0)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (0.17.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (1.49.0rc1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=2.0.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-cloud-bigquery<4,>=2.0.0->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (2.7.2)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.12.4 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-cloud-bigtable<3,>=2.19.0->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (0.12.7)\n",
      "Requirement already satisfied: google-crc32c<2.0.0dev,>=1.5.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-cloud-bigtable<3,>=2.19.0->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (1.7.1)\n",
      "Requirement already satisfied: overrides<8.0.0,>=6.0.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-cloud-pubsublite<2,>=1.2.0->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (7.7.0)\n",
      "Collecting grpc-google-iam-v1<1.0.0,>=0.12.4 (from google-cloud-bigtable<3,>=2.19.0->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization])\n",
      "  Downloading grpc_google_iam_v1-0.14.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: sqlparse>=0.4.4 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (0.5.3)\n",
      "Requirement already satisfied: grpc-interceptor>=0.15.4 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (0.15.4)\n",
      "Requirement already satisfied: docopt in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (0.6.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from httplib2<0.23.0,>=0.8->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (3.2.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from ipython<8,>=7->tensorflow-data-validation[visualization]) (80.9.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from ipython<8,>=7->tensorflow-data-validation[visualization]) (0.19.2)\n",
      "Requirement already satisfied: decorator in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from ipython<8,>=7->tensorflow-data-validation[visualization]) (5.2.1)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from ipython<8,>=7->tensorflow-data-validation[visualization]) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from ipython<8,>=7->tensorflow-data-validation[visualization]) (5.14.3)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from ipython<8,>=7->tensorflow-data-validation[visualization]) (3.0.52)\n",
      "Requirement already satisfied: pygments in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from ipython<8,>=7->tensorflow-data-validation[visualization]) (2.19.2)\n",
      "Collecting backcall (from ipython<8,>=7->tensorflow-data-validation[visualization])\n",
      "  Downloading backcall-0.2.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from ipython<8,>=7->tensorflow-data-validation[visualization]) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from ipython<8,>=7->tensorflow-data-validation[visualization]) (4.9.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (0.27.1)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8,>=7->tensorflow-data-validation[visualization]) (0.2.14)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (2.41.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (0.4.2)\n",
      "Collecting PyJWT>=2.9.0 (from redis<6,>=5.0.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization])\n",
      "  Downloading PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: async-timeout>=4.0.3 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from redis<6,>=5.0.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (5.0.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from requests<3.0.0,>=2.32.4->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from requests<3.0.0,>=2.32.4->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from requests<3.0.0,>=2.32.4->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from requests<3.0.0,>=2.32.4->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (2025.10.5)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (0.6.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tensorflow-data-validation[visualization]) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tensorflow-data-validation[visualization]) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tensorflow-data-validation[visualization]) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tensorflow-data-validation[visualization]) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tensorflow-data-validation[visualization]) (3.14.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tensorflow-data-validation[visualization]) (18.1.1)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow<2.17,>=2.16->tensorflow-data-validation[visualization])\n",
      "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tensorflow-data-validation[visualization]) (3.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tensorflow-data-validation[visualization]) (3.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tensorflow-data-validation[visualization]) (1.17.3)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow<2.17,>=2.16->tensorflow-data-validation[visualization])\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow<2.17,>=2.16->tensorflow-data-validation[visualization])\n",
      "  Downloading keras-3.12.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tensorflow-data-validation[visualization]) (0.29.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tensorflow-data-validation[visualization]) (3.9)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tensorflow-data-validation[visualization])\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tensorflow-data-validation[visualization]) (3.1.3)\n",
      "Collecting protobuf<5,>=3.20.3 (from tensorflow-data-validation[visualization])\n",
      "  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n",
      "Collecting google-api-python-client<2,>=1.7.11 (from tfx-bsl<1.17,>=1.16.0->tensorflow-data-validation[visualization])\n",
      "  Downloading google_api_python_client-1.12.11-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting tensorflow-serving-api<3,>=2.13.0 (from tfx-bsl<1.17,>=1.16.0->tensorflow-data-validation[visualization])\n",
      "  Downloading tensorflow_serving_api-2.19.1-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting uritemplate<4dev,>=3.0.0 (from google-api-python-client<2,>=1.7.11->tfx-bsl<1.17,>=1.16.0->tensorflow-data-validation[visualization])\n",
      "  Downloading uritemplate-3.0.1-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "INFO: pip is looking at multiple versions of tensorflow-serving-api to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorflow-serving-api<3,>=2.13.0 (from tfx-bsl<1.17,>=1.16.0->tensorflow-data-validation[visualization])\n",
      "  Downloading tensorflow_serving_api-2.19.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "  Downloading tensorflow_serving_api-2.18.1-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "  Downloading tensorflow_serving_api-2.18.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "  Downloading tensorflow_serving_api-2.17.1-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "  Downloading tensorflow_serving_api-2.17.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "  Downloading tensorflow_serving_api-2.16.1-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.17,>=2.16->tensorflow-data-validation[visualization]) (0.45.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from cffi>=1.12->cryptography<48.0.0,>=39.0.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (2.22)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from jedi>=0.16->ipython<8,>=7->tensorflow-data-validation[visualization]) (0.8.5)\n",
      "Requirement already satisfied: rich in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tensorflow-data-validation[visualization]) (14.1.0)\n",
      "Collecting namex (from keras>=3.0.0->tensorflow<2.17,>=2.16->tensorflow-data-validation[visualization])\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow<2.17,>=2.16->tensorflow-data-validation[visualization])\n",
      "  Downloading optree-0.17.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (33 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from pexpect>4.3->ipython<8,>=7->tensorflow-data-validation[visualization]) (0.7.0)\n",
      "Collecting scramp>=1.4.5 (from pg8000>=1.31.1->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization])\n",
      "  Downloading scramp-1.4.6-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting asn1crypto>=1.5.1 (from scramp>=1.4.5->pg8000>=1.31.1->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization])\n",
      "  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tensorflow-data-validation[visualization]) (3.0.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from aiohttp->cloud-sql-python-connector<2.0.0,>=1.18.2->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from aiohttp->cloud-sql-python-connector<2.0.0,>=1.18.2->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (1.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from aiohttp->cloud-sql-python-connector<2.0.0,>=1.18.2->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from aiohttp->cloud-sql-python-connector<2.0.0,>=1.18.2->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from aiohttp->cloud-sql-python-connector<2.0.0,>=1.18.2->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from aiohttp->cloud-sql-python-connector<2.0.0,>=1.18.2->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (1.22.0)\n",
      "Requirement already satisfied: keyring in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (25.6.0)\n",
      "Requirement already satisfied: pluggy in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (1.6.0)\n",
      "Requirement already satisfied: SecretStorage>=3.2 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (3.4.0)\n",
      "Requirement already satisfied: jeepney>=0.4.2 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (0.9.0)\n",
      "Requirement already satisfied: importlib_metadata>=4.11.4 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (8.7.0)\n",
      "Requirement already satisfied: jaraco.classes in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (3.4.0)\n",
      "Requirement already satisfied: jaraco.functools in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (4.3.0)\n",
      "Requirement already satisfied: jaraco.context in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (6.0.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from importlib_metadata>=4.11.4->keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (3.23.0)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from jaraco.classes->keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (10.8.0)\n",
      "Requirement already satisfied: backports.tarfile in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from jaraco.context->keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47; python_version < \"3.11\"->tensorflow-data-validation[visualization]) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tensorflow-data-validation[visualization]) (4.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tensorflow-data-validation[visualization]) (0.1.2)\n",
      "Downloading tensorflow_data_validation-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.0/19.0 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading apache_beam-2.69.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m120.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading beartype-0.21.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cloud_sql_python_connector-1.18.5-py3-none-any.whl (49 kB)\n",
      "Downloading google_cloud_bigtable-2.34.0-py3-none-any.whl (537 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m537.0/537.0 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_datastore-2.21.0-py2.py3-none-any.whl (208 kB)\n",
      "Downloading google_cloud_language-2.18.0-py3-none-any.whl (168 kB)\n",
      "Downloading google_cloud_secret_manager-2.25.0-py3-none-any.whl (218 kB)\n",
      "Downloading google_cloud_videointelligence-2.17.0-py3-none-any.whl (276 kB)\n",
      "Downloading grpc_google_iam_v1-0.14.3-py3-none-any.whl (32 kB)\n",
      "Downloading grpcio-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m129.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ipython-7.34.0-py3-none-any.whl (793 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m793.8/793.8 kB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpickle-3.4.2-py3-none-any.whl (46 kB)\n",
      "Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m108.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-10.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.9/35.9 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow_hotfix-0.7-py3-none-any.whl (7.9 kB)\n",
      "Downloading redis-5.3.1-py3-none-any.whl (272 kB)\n",
      "Downloading tensorflow-2.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (590.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_metadata-1.16.1-py3-none-any.whl (28 kB)\n",
      "Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tfx_bsl-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.5/22.5 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_api_python_client-1.12.11-py2.py3-none-any.whl (62 kB)\n",
      "Downloading tensorflow_serving_api-2.16.1-py2.py3-none-any.whl (26 kB)\n",
      "Downloading uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\n",
      "Downloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
      "Downloading keras-3.12.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pg8000-1.31.5-py3-none-any.whl (57 kB)\n",
      "Downloading PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
      "Downloading pymysql-1.1.2-py3-none-any.whl (45 kB)\n",
      "Downloading python_tds-1.17.1-py3-none-any.whl (86 kB)\n",
      "Downloading scramp-1.4.6-py3-none-any.whl (12 kB)\n",
      "Downloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.17.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (387 kB)\n",
      "Building wheels for collected packages: pyfarmhash\n",
      "\u001b[33m  DEPRECATION: Building 'pyfarmhash' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'pyfarmhash'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for pyfarmhash (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyfarmhash: filename=pyfarmhash-0.3.2-cp310-cp310-linux_x86_64.whl size=13938 sha256=9066f1b90854aad09dce53ce7dff171900af1c1cf8cbd7a55627714b7b56514d\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/e0/08/da/f66b1f3258fe3f1e767b2136c5444dbfa9fa3f7944cc5e1983\n",
      "Successfully built pyfarmhash\n",
      "Installing collected packages: sortedcontainers, python-tds, pyfarmhash, namex, backcall, asn1crypto, uritemplate, tensorboard-data-server, scramp, PyMySQL, PyJWT, pyarrow-hotfix, pyarrow, protobuf, optree, ml-dtypes, jsonpickle, grpcio, dnspython, beartype, tensorflow-metadata, tensorboard, redis, pg8000, pandas, ipython, keras, tensorflow, grpc-google-iam-v1, google-api-python-client, cloud-sql-python-connector, apache-beam, tensorflow-serving-api, google-cloud-videointelligence, google-cloud-secret-manager, google-cloud-language, google-cloud-datastore, google-cloud-bigtable, tfx-bsl, tensorflow-data-validation\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/40\u001b[0m [pyarrow]hotfix]a-server]\u001b[33m  WARNING: The script plasma_store is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/40\u001b[0m [tensorboard]\u001b[33m  WARNING: The script tensorboard is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/40\u001b[0m [ipython]\u001b[33m  WARNING: The scripts iptest, iptest3, ipython and ipython3 are installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m27/40\u001b[0m [tensorflow]\u001b[33m  WARNING: The scripts import_pb_to_tensorboard, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40/40\u001b[0m [tensorflow-data-validation]lidation]ble]]ager]]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-transform 0.14.0 requires tensorflow-metadata<0.15,>=0.14, but you have tensorflow-metadata 1.16.1 which is incompatible.\n",
      "visions 0.8.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyJWT-2.10.1 PyMySQL-1.1.2 apache-beam-2.69.0 asn1crypto-1.5.1 backcall-0.2.0 beartype-0.21.0 cloud-sql-python-connector-1.18.5 dnspython-2.8.0 google-api-python-client-1.12.11 google-cloud-bigtable-2.34.0 google-cloud-datastore-2.21.0 google-cloud-language-2.18.0 google-cloud-secret-manager-2.25.0 google-cloud-videointelligence-2.17.0 grpc-google-iam-v1-0.14.3 grpcio-1.65.5 ipython-7.34.0 jsonpickle-3.4.2 keras-3.12.0 ml-dtypes-0.3.2 namex-0.1.0 optree-0.17.0 pandas-1.5.3 pg8000-1.31.5 protobuf-3.20.3 pyarrow-10.0.1 pyarrow-hotfix-0.7 pyfarmhash-0.3.2 python-tds-1.17.1 redis-5.3.1 scramp-1.4.6 sortedcontainers-2.4.0 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.2 tensorflow-data-validation-1.16.1 tensorflow-metadata-1.16.1 tensorflow-serving-api-2.16.1 tfx-bsl-1.16.1 uritemplate-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --user tensorflow-data-validation[visualization] dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "r8S3ublR7Ay8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 15:55:10.965894: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-01 15:55:16.654834: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/lib/x86_64-linux-gnu/:/opt/conda/lib\n",
      "2025-11-01 15:55:16.655158: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/lib/x86_64-linux-gnu/:/opt/conda/lib\n",
      "2025-11-01 15:55:16.655173: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow and TensorFlow Datasets\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SkocY8tgRd3H",
    "outputId": "93f81b8a-4cd1-4a44-acaf-b2c3fd50d404"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "# Here we'll show the currently installed version of TensorFlow\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hXhefksNKk2I"
   },
   "source": [
    "## Download the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtnnUwvmB3X5"
   },
   "source": [
    "Download the MNIST dataset and load it from [TensorFlow Datasets](https://www.tensorflow.org/datasets). This returns a dataset in `tf.data` format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHAPqG8MtS8M"
   },
   "source": [
    "Setting `with_info` to `True` includes the metadata for the entire dataset, which is being saved here to `info`.\n",
    "Among other things, this metadata object includes the number of train and test examples. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222,
     "referenced_widgets": [
      "87a63a803ef64822bd91f083558278ce",
      "29cd8bd6a1654ddb890f8e26afbbb574",
      "954d6bb981e64053a56b71336c7c76b6",
      "b1a06090e773431e9a7f0c2c89ecda19",
      "5dfab89c78d14363bd424513d9bc8a7e",
      "84909d8b4a9c4c8586319b7f2482e3a7",
      "4dea4d007cac494da0526c363d96e94b",
      "eac25bd6c24144a9be4cdc3c46d3031f"
     ]
    },
    "id": "iXMJ3G9NB3X6",
    "outputId": "ad3818a6-0c79-4b89-82ff-ec63f9ff0234"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /home/jupyter/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccb8acb4bcb54d24b0b6cc350448632e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...:   0%|          | 0/5 [00:00<?, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to /home/jupyter/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 15:55:22.410638: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/lib/x86_64-linux-gnu/:/opt/conda/lib\n",
      "2025-11-01 15:55:22.410684: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2025-11-01 15:55:22.410719: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (lab-workbench): /proc/driver/nvidia/version does not exist\n",
      "2025-11-01 15:55:22.413692: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Loads the named dataset into a tf.data.Dataset\n",
    "# TODO\n",
    "datasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True)\n",
    "\n",
    "mnist_train, mnist_test = datasets['train'], datasets['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GrjVhv-eKuHD"
   },
   "source": [
    "## Define distribution strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TlH8vx6BB3X9"
   },
   "source": [
    "Create a `MirroredStrategy` object. This will handle distribution, and provides a context manager (`tf.distribute.MirroredStrategy.scope`) to build your model inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4j0tdf4YB3X9",
    "outputId": "e20ea159-5088-4776-be9e-a4a71787a7bf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "# Synchronous training across multiple replicas on one machine.\n",
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cY3KA_h2iVfN",
    "outputId": "eaf4aec4-694f-4005-a08e-7b62a84e349a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 1\n"
     ]
    }
   ],
   "source": [
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNbPv0yAleW8"
   },
   "source": [
    "## Setup input pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "psozqcuptXhK"
   },
   "source": [
    "When training a model with multiple GPUs, you can use the extra computing power effectively by increasing the batch size. In general, use the largest batch size that fits the GPU memory, and tune the learning rate accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "p1xWxKcnhar9"
   },
   "outputs": [],
   "source": [
    "# You can also do info.splits.total_num_examples to get the total\n",
    "# number of examples in the dataset.\n",
    "\n",
    "num_train_examples = info.splits['train'].num_examples\n",
    "num_test_examples = info.splits['test'].num_examples\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "BATCH_SIZE_PER_REPLICA = 64\n",
    "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Wm5rsL2KoDF"
   },
   "source": [
    "Pixel values, which are 0-255, [have to be normalized to the 0-1 range](https://en.wikipedia.org/wiki/Feature_scaling). Define this scale in a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Eo9a46ZeJCkm"
   },
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  image /= 255\n",
    "\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZCa5RLc5A91"
   },
   "source": [
    "Apply this function to the training and test data, shuffle the training data, and [batch it for training](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#batch). Notice we are also keeping an in-memory cache of the training data to improve performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gRZu2maChwdT"
   },
   "outputs": [],
   "source": [
    "train_dataset = mnist_train.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xsComp8Kz5H"
   },
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BnQYQTpB3YA"
   },
   "source": [
    "Create and compile the Keras model in the context of `strategy.scope`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IexhL_vIB3YA",
    "outputId": "7ea5ab8a-c328-4a14-bd79-8ba35e598f7d"
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
    "      tf.keras.layers.MaxPooling2D(),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(64, activation='relu'),\n",
    "      tf.keras.layers.Dense(10)\n",
    "  ])\n",
    "\n",
    "# Configures the model for training.\n",
    "# TODO\n",
    "  model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8i6OU5W9Vy2u"
   },
   "source": [
    "## Define the callbacks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YOXO5nvvK3US"
   },
   "source": [
    "The callbacks used here are:\n",
    "\n",
    "*   *TensorBoard*: This callback writes a log for TensorBoard which allows you to visualize the graphs.\n",
    "*   *Model Checkpoint*: This callback saves the model after every epoch.\n",
    "*   *Learning Rate Scheduler*: Using this callback, you can schedule the learning rate to change after every epoch/batch.\n",
    "\n",
    "For illustrative purposes, add a print callback to display the *learning rate* in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "A9bwLCcXzSgy"
   },
   "outputs": [],
   "source": [
    "# Define the checkpoint directory to store the checkpoints\n",
    "\n",
    "# TODO\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "# TODO\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "wpU-BEdzJDbK"
   },
   "outputs": [],
   "source": [
    "# Function for decaying the learning rate.\n",
    "# You can define any decay function you need.\n",
    "def decay(epoch):\n",
    "  if epoch < 3:\n",
    "    return 1e-3\n",
    "  elif epoch >= 3 and epoch < 7:\n",
    "    return 1e-4\n",
    "  else:\n",
    "    return 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "jKhiMgXtKq2w"
   },
   "outputs": [],
   "source": [
    "# Callback for printing the LR at the end of each epoch.\n",
    "class PrintLR(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    print('\\nLearning rate for epoch {} is {}'.format(epoch + 1,\n",
    "                                                      model.optimizer.lr.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "YVqAbR6YyNQh"
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n",
    "                                       save_weights_only=True),\n",
    "    tf.keras.callbacks.LearningRateScheduler(decay),\n",
    "    PrintLR()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70HXgDQmK46q"
   },
   "source": [
    "## Train and evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6EophnOAB3YD"
   },
   "source": [
    "Now, train the model in the usual way, calling `fit` on the model and passing in the dataset created at the beginning of the tutorial. This step is the same whether you are distributing the training or not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7MVw_6CqB3YD",
    "outputId": "1d72cbdc-11aa-4beb-eeb4-dcfcba5fce72"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 15:55:24.391972: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:549] The `assert_cardinality` transformation is currently not handled by the auto-shard rewrite and will be removed.\n",
      "2025-11-01 15:55:24.549202: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "935/938 [============================>.] - ETA: 0s - loss: 0.1991 - accuracy: 0.9417\n",
      "Learning rate for epoch 1 is 0.0010000000474974513\n",
      "938/938 [==============================] - 24s 21ms/step - loss: 0.1988 - accuracy: 0.9418 - lr: 0.0010\n",
      "Epoch 2/12\n",
      "936/938 [============================>.] - ETA: 0s - loss: 0.0662 - accuracy: 0.9807\n",
      "Learning rate for epoch 2 is 0.0010000000474974513\n",
      "938/938 [==============================] - 19s 21ms/step - loss: 0.0661 - accuracy: 0.9807 - lr: 0.0010\n",
      "Epoch 3/12\n",
      "  7/938 [..............................] - ETA: 17s - loss: 0.0511 - accuracy: 0.9866"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 15:56:08.334612: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "937/938 [============================>.] - ETA: 0s - loss: 0.0465 - accuracy: 0.9856\n",
      "Learning rate for epoch 3 is 0.0010000000474974513\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0465 - accuracy: 0.9856 - lr: 0.0010\n",
      "Epoch 4/12\n",
      "938/938 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 0.9933\n",
      "Learning rate for epoch 4 is 9.999999747378752e-05\n",
      "938/938 [==============================] - 21s 23ms/step - loss: 0.0251 - accuracy: 0.9933 - lr: 1.0000e-04\n",
      "Epoch 5/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 15:56:47.679433: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "936/938 [============================>.] - ETA: 0s - loss: 0.0215 - accuracy: 0.9945\n",
      "Learning rate for epoch 5 is 9.999999747378752e-05\n",
      "938/938 [==============================] - 42s 44ms/step - loss: 0.0215 - accuracy: 0.9945 - lr: 1.0000e-04\n",
      "Epoch 6/12\n",
      "  7/938 [..............................] - ETA: 17s - loss: 0.0116 - accuracy: 0.9955"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 15:57:29.741552: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.9949\n",
      "Learning rate for epoch 6 is 9.999999747378752e-05\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0199 - accuracy: 0.9949 - lr: 1.0000e-04\n",
      "Epoch 7/12\n",
      "937/938 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.9953\n",
      "Learning rate for epoch 7 is 9.999999747378752e-05\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.0182 - accuracy: 0.9953 - lr: 1.0000e-04\n",
      "Epoch 8/12\n",
      "  3/938 [..............................] - ETA: 23s - loss: 0.0153 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 15:58:06.973141: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "936/938 [============================>.] - ETA: 0s - loss: 0.0156 - accuracy: 0.9966\n",
      "Learning rate for epoch 8 is 9.999999747378752e-06\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0156 - accuracy: 0.9966 - lr: 1.0000e-05\n",
      "Epoch 9/12\n",
      "937/938 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9966\n",
      "Learning rate for epoch 9 is 9.999999747378752e-06\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0153 - accuracy: 0.9966 - lr: 1.0000e-05\n",
      "Epoch 10/12\n",
      "  7/938 [..............................] - ETA: 18s - loss: 0.0168 - accuracy: 0.9933"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 15:58:43.060407: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "546/938 [================>.............] - ETA: 7s - loss: 0.0170 - accuracy: 0.9961"
     ]
    }
   ],
   "source": [
    "# Train the model with the new callback\n",
    "# TODO\n",
    "model.fit(train_dataset, epochs=12, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUcWAUUupIvG"
   },
   "source": [
    "As you can see below, the checkpoints are getting saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JQ4zeSTxKEhB",
    "outputId": "6468c115-bac6-4952-bb16-a85f01297388"
   },
   "outputs": [],
   "source": [
    "# check the checkpoint directory\n",
    "!ls {checkpoint_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qor53h7FpMke"
   },
   "source": [
    "To see how the model perform, load the latest checkpoint and call `evaluate` on the test data.\n",
    "\n",
    "Call `evaluate` as before using appropriate datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JtEwxiTgpQoP",
    "outputId": "4c0cd338-ce12-4715-8806-2fcdbfe8ecd8"
   },
   "outputs": [],
   "source": [
    "# Loads the weights\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "eval_loss, eval_acc = model.evaluate(eval_dataset)\n",
    "\n",
    "print('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIeF2RWfYu4N"
   },
   "source": [
    "To see the output, you can download and view the TensorBoard logs at the terminal.\n",
    "\n",
    "```\n",
    "$ tensorboard --logdir=path/to/log-directory\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LnyscOkvKKBR",
    "outputId": "624c3432-b986-459c-aad1-024b13d74e10"
   },
   "outputs": [],
   "source": [
    "!ls -sh ./logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBLlogrDvMgg"
   },
   "source": [
    "## Export to SavedModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xa87y_A0vRma"
   },
   "source": [
    "Export the graph and the variables to the platform-agnostic SavedModel format. After your model is saved, you can load it with or without the scope.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h8Q4MKOLwG7K"
   },
   "outputs": [],
   "source": [
    "path = 'saved_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4HvcDmVsvQoa",
    "outputId": "35b708b8-8829-42cd-c796-375fd17f0752"
   },
   "outputs": [],
   "source": [
    "# Save the entire model as a SavedModel.\n",
    "# TODO\n",
    "model.save(path, save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKJT4w5JwVPI"
   },
   "source": [
    "Load the model without `strategy.scope`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T_gT0RbRvQ3o",
    "outputId": "3f77b369-3132-4407-f217-57e612f22362"
   },
   "outputs": [],
   "source": [
    "unreplicated_model = tf.keras.models.load_model(path)\n",
    "\n",
    "unreplicated_model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "eval_loss, eval_acc = unreplicated_model.evaluate(eval_dataset)\n",
    "\n",
    "print('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBLzcRF0wbDe"
   },
   "source": [
    "Load the model with `strategy.scope`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BBVo3WGGwd9a",
    "outputId": "398d611e-1407-4f76-bd7c-aa33fc907023"
   },
   "outputs": [],
   "source": [
    "# Recreate the exact same model, including its weights and the optimizer\n",
    "with strategy.scope():\n",
    "  replicated_model = tf.keras.models.load_model(path)\n",
    "  replicated_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                           optimizer=tf.keras.optimizers.Adam(),\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "  eval_loss, eval_acc = replicated_model.evaluate(eval_dataset)\n",
    "  print ('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUZwaz4AKjtD"
   },
   "source": [
    "### Examples and Tutorials\n",
    "Here are some examples for using distribution strategy with keras fit/compile:\n",
    "1. [Transformer](https://github.com/tensorflow/models/blob/master/official/nlp/transformer/transformer_main.py) example trained using `tf.distribute.MirroredStrategy`\n",
    "2. [NCF](https://github.com/tensorflow/models/blob/master/official/recommendation/ncf_keras_main.py) example trained using `tf.distribute.MirroredStrategy`.\n",
    "\n",
    "More examples listed in the [Distribution strategy guide](https://raw.githubusercontent.com/tensorflow/docs/master/site/en/guide/distributed_training.ipynb#examples_and_tutorials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8uNqWRdDMl5S"
   },
   "source": [
    "## Next steps\n",
    "\n",
    "* Read the [distribution strategy guide](https://raw.githubusercontent.com/tensorflow/docs/master/site/en/guide/distributed_training.ipynb).\n",
    "* Read the [Distributed Training with Custom Training Loops](https://raw.githubusercontent.com/tensorflow/docs/master/site/en/tutorials/distribute/custom_training.ipynb) tutorial.\n",
    "* Visit the [Performance section](https://raw.githubusercontent.com/tensorflow/docs/master/site/en/guide/function.ipynb) in the guide to learn more about other strategies and [tools](https://raw.githubusercontent.com/tensorflow/docs/master/site/en/guide/profiler.md) you can use to optimize the performance of your TensorFlow models.\n",
    "\n",
    "Note: `tf.distribute.Strategy` is actively under development and we will be adding more examples and tutorials in the near future. Please give it a try. We welcome your feedback via [issues on GitHub](https://github.com/tensorflow/tensorflow/issues/new)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "keras.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-env-tensorflow-tensorflow",
   "name": "workbench-notebooks.m134",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m134"
  },
  "kernelspec": {
   "display_name": "TensorFlow 2-11 (Local)",
   "language": "python",
   "name": "conda-env-tensorflow-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
